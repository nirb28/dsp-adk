# JWT Configuration
JWT_SERVICE_URL=http://localhost:5000
JWT_SECRET_KEY=your-secret-key-here
JWT_ALGORITHM=HS256

# Server Configuration
HOST=0.0.0.0
PORT=8100
DEBUG=true

# Storage Configuration
STORAGE_PATH=./data
AGENTS_DIR=./data/agents
TOOLS_DIR=./data/tools
GRAPHS_DIR=./data/graphs
MCP_SERVERS_DIR=./data/mcp_servers

# Logging
LOG_LEVEL=DEBUG
# Enable verbose payload logging (logs ALL request/response payloads - use only for debugging)
# WARNING: This generates very large log files and has performance impact
VERBOSE_LOGGING=false

# OpenTelemetry Configuration
# Set OTEL_ENABLED=true to enable telemetry export to Jaeger/OTEL collector
# Start Jaeger with: docker run -d --name jaeger -e COLLECTOR_OTLP_ENABLED=true -p 16686:16686 -p 4318:4318 jaegertracing/all-in-one:latest
# View traces at: http://localhost:16686
OTEL_ENABLED=true
OTEL_ENDPOINT=http://localhost:4318
OTEL_SERVICE_NAME=adk
OTEL_EXPORT_INTERVAL=5000
OTEL_MAX_TRACES=10000
OTEL_MAX_SPANS=100000

# LLM Configuration (for agents)
# Use ${VARIABLE_NAME} syntax to reference other environment variables
# All ${VARIABLE} references are automatically resolved when configs are loaded
#
# Choose one provider and uncomment its section:

# OpenAI (default)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
LLM_ENDPOINT=https://api.openai.com/v1
LLM_API_KEY=sk-your-openai-key-here

# Groq (alternative - uncomment to use)
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.1-70b-versatile
# LLM_ENDPOINT=https://api.groq.com/openai/v1
# LLM_API_KEY=gsk_your-groq-key-here

# NVIDIA (alternative - uncomment to use)
# LLM_PROVIDER=nvidia
# LLM_MODEL=meta/llama-3.1-70b-instruct
# LLM_ENDPOINT=https://integrate.api.nvidia.com/v1
# LLM_API_KEY=nvapi-your-nvidia-key-here

# Brave Search API (for web-search tool)
BRAVE_API_KEY=your-brave-api-key-here

# Search API Configuration (supports variable references)
# You can reference other environment variables using $VAR_NAME or ${VAR_NAME} syntax
SEARCH_API_ENDPOINT=https://api.search.brave.com/res/v1/web/search
SEARCH_API_KEY=$BRAVE_API_KEY
